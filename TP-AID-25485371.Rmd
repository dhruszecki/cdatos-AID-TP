---
title: "TP-AID-25485371"
author: "Darío Hruszecki"
date: "8/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Librerias
```{r}
library(readxl)
library(here)
library(dplyr)
library(ggplot2)
library(gridExtra) 
library(mvnormtest)
library(biotools)
library(corpcor)
library(Hotelling)
library(DescTools)
library(MASS)
library(reshape2) 
library(knitr) 
library(corrplot)
library(htmltools)
library(ggrepel)
#library(devtools)
library(ggbiplot)
library(nortest)
library(MASS)
#library(klaR)
library(caret)
library(e1071)
library(cluster)
library(pracma)
library(ROCR)
library(cluster)
library(factoextra)
library(NbClust)
library(car)
```

#Carga de bases
```{r}
here::here()
df_accidentes <- read_excel(here::here("ds", "bases.xlsx"), sheet = "accidente")
colnames(df_accidentes)[3] <- "edad.conductor"
df_accidentes = df_accidentes[,c(1:5)]
df_accidentes[,"grave"]=as.factor(df_accidentes$grave)
df_accidentes

```

# Subselección del dataset de acuerdo a mi DNI
```{r}
dni = 25485371

n_accidentes = round(0.9* nrow(df_accidentes)) #80% de los datos para base accidentes
n_telecom = round(0.9* nrow(df_telecom)) #90% de los datos para base telecomunicaciones

set.seed(dni);cuales = sample(1:nrow(df_accidentes), size=n_accidentes, replace=FALSE)
df_accidentes = df_accidentes[cuales,]

df_accidentes[,"grave"]=as.factor(df_accidentes$grave)

df_telecom

```

# Accidentes

## Resumen del dataset
```{r}
str(df_accidentes)
summary(df_accidentes)
```

## Gráficos de barra e Histogramas
```{r}
names(df_accidentes)
ggplot(data=df_accidentes, aes(x=antigüedad)) + 
    geom_bar()
ggplot(data=df_accidentes, aes(x=edad.conductor)) + 
    geom_bar()
ggplot(data=df_accidentes, aes(x=potencia)) + 
    geom_bar()
ggplot(data=df_accidentes, aes(x=grave)) + 
    geom_bar()
```
## Partición train y val 70-30 de forma estratificada por variable a predecir.
```{r}
set.seed(25485371)
train <- data.frame(createDataPartition(y = df_accidentes$grave, p = 0.7, list = FALSE, times = 1))
train_ind = train$Resample1
sum(as.numeric(df_accidentes[train_ind,]$grave)-1)/nrow(df_accidentes[train_ind,]) # % en entrenamiento
sum(as.numeric(df_accidentes[-train_ind,]$grave)-1)/nrow(df_accidentes[-train_ind,]) # % en validación

df_accidentes_train=df_accidentes[train_ind,] 
df_accidentes_val=df_accidentes[-train_ind,] 

table(df_accidentes_train$grave)/nrow(df_accidentes_train) # Distribución porcentual en entrenamiento
table(df_accidentes_val$grave)/nrow(df_accidentes_val) # Distribución porcentual en validación
table(df_accidentes$grave)/nrow(df_accidentes) # Distribución porcentual en el total

df_accidentes_train[,"grave"]=as.factor(df_accidentes_train$grave)

df_accidentes_val[,"grave"]=as.factor(df_accidentes_val$grave)
```

#Diagrama de dispersión
```{r}
plot(df_accidentes[,c(2,3,4)])
```
#Histogramas y gráficos de barras
```{r}
ggplot(data = df_accidentes, aes(x = antigüedad, fill = grave)) + 
  geom_histogram(position = "identity", alpha = 0.5)
ggplot(data = df_accidentes, aes(x = edad.conductor, fill = grave)) + 
  geom_histogram(position = "identity", alpha = 0.5)
ggplot(data = df_accidentes, aes(x = potencia, fill = grave)) + 
  geom_histogram(position = "identity", alpha = 0.5)
```

#Dispersograma de las variables numéricas, mostrando a qué clase pertenecen 
```{r}
pairs(x = df_accidentes[, c(2,3,4)], col = c("green3", "red")[df_accidentes$grave], pch = 19)
```
#Boxplot para cada una de las variables numéricas por clase
```{r}
ggplot(df_accidentes,aes(x=grave,y=antigüedad,fill=grave))+
geom_boxplot()+
xlab("")+
scale_fill_brewer(palette="Pastel1",name="Accidente Grave",
breaks=c("0","1"),labels=c("no","sí"))+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())

ggplot(df_accidentes,aes(x=grave,y=edad.conductor,fill=grave))+
geom_boxplot()+
xlab("")+
scale_fill_brewer(palette="Pastel1",name="Accidente Grave",
breaks=c("0","1"),labels=c("no","sí"))+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())

ggplot(df_accidentes,aes(x=grave,y=potencia,fill=grave))+
geom_boxplot()+
xlab("")+
scale_fill_brewer(palette="Pastel1",name="Accidente Grave",
breaks=c("0","1"),labels=c("no","sí"))+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())
```

#Analizamos normalidad multivariada para variables numéricas:
```{r}
mshapiro.test(t(df_accidentes[,c(2,3,4)]))
#No es normal multivariada
```
#Verificamos el supuesto de normalidad multivariada por población/grupo. Vemos que el mismo no se cumple.
```{r}
mshapiro.test(t(df_accidentes[df_accidentes$grave==0,c(2,3,4)]))

mshapiro.test(t(df_accidentes[df_accidentes$grave==1,c(2,3,4)]))
#No se cumple normalidad multivariada
```

#Verificamos el supuesto de homoscedasticidad multivariada, vemos que el mismo no se cumple.
```{r}
boxM(data = df_accidentes[, c(2,3,4)], grouping = df_accidentes$grave)
#No se cumple homocedasticidad
```

#Prueba de igualdad de vectores medios. No se cumplen los supuestos para que el test tenga validez estadística.

```{r}
fitProd = hotelling.test(.~ grave, data=df_accidentes[,c(2,3,4,5)]) 
fitProd 
```


#Gráficos de densidad.
```{r}
names(df_accidentes)
ggplot(data = df_accidentes, aes(x = antigüedad)) + 
  geom_density(aes(colour = grave)) + theme_bw() 
ggplot(data = df_accidentes, aes(x = edad.conductor)) + 
  geom_density(aes(colour = grave)) + theme_bw() 
ggplot(data = df_accidentes, aes(x = potencia)) + 
  geom_density(aes(colour = grave)) + theme_bw() 

#Matrices de correlaciones variables numéricas
round(cor(df_accidentes[,c(2,3,4)]),5)
```

#Correlograma
```{r}
a= cor(df_accidentes[,c(2,3,4)])
corrplot(a, method = "number")
```

#Correlogramas para variables por cada tipo
```{r}
a= cor(df_accidentes[df_accidentes$grave==0,c(2,3,4)])
b= cor(df_accidentes[df_accidentes$grave==1,c(2,3,4)])
par(mfrow= c(1,2))
corrplot(a, cl.cex=0.5)
corrplot(b, cl.cex=0.5)
```

#Si bien no es válida como matriz de correlación, nos permite observar  que no hay asociación entre variables y target
```{r}
f=as.data.frame(as.numeric(df_accidentes$grave))
names(f)="grave"
f2 = cbind(f,df_accidentes[,2:4])
f2[,1]= f2[,1]-1
b= cor(f2)
corrplot(b, method = "number")
```

# Análisis de componentes principales
```{r}
a= cor(df_accidentes[,c(2,3,4)])
desc_mat_cor = eigen(a)
autovalores_cor = desc_mat_cor$values
round(autovalores_cor,2)
```

## Variabilidad explicada por cada autovalor
```{r}
variabilidad_cor = autovalores_cor/sum(autovalores_cor)
round(variabilidad_cor,2)
```

## Componentes principales

```{r echo=TRUE}
datos.pc = prcomp(df_accidentes[,c(2,3,4)],scale = TRUE)
#datos.pc$sdev #raiz cuadrada de los autovalores
round(datos.pc$sdev^2,2)
```

```{r echo=TRUE}
round(datos.pc$rotation,2) #autovectores (en columna)
```

```{r echo=TRUE}
round(datos.pc$center,2) #vector de medias 
```

```{r echo=TRUE}
round(datos.pc$scale,2) #vector de desvios
```

```{r echo=TRUE}
#loadings
carga1 = data.frame(cbind(X=1:(length(datos.pc)-1),
                          primeracarga=data.frame(datos.pc$rotation)[,1]))
carga2 = data.frame(cbind(X=1:(length(datos.pc)-1),
                          segundacarga=data.frame(datos.pc$rotation)[,2]))
round(cbind(carga1,carga2),2)
```

```{r echo=TRUE}
ggplot(carga1, aes(X,primeracarga) ,
       fill=tramo ) + geom_bar ( stat="identity" ,
       position="dodge" ,
       fill ="royalblue" ,
       width =0.5 ) + xlab( 'Tramo' ) + ylab('Primeracarga ' )

```

```{r echo=TRUE}
ggplot( carga2 , aes ( X , segundacarga ) ,
        fill =X ) + geom_bar ( stat="identity" , position="dodge" ,
           fill ="royalblue" ,
           width =0.5 ) +
xlab('Tramo') + ylab('Segundacarga')

```

```{r echo=TRUE}
ggbiplot(datos.pc, obs.scale=1 ,var.scale=1,alpha=0.5)
```
#Biplot con variables numéricas
```{r echo=TRUE}
ggbiplot(datos.pc, obs.scale=0.1 ,var.scale=1,
         alpha=0.3,groups=factor(df_accidentes$grave)) +
  scale_color_manual(name="Accidente Grave", values=c("black", "red","green"),labels=c("NO", "SI")) +  
theme(legend.direction ="horizontal", legend.position = "top")
```

#Análisis discriminante lineal, aún sin validez estadística se aplica para ver cómo clasifica.
```{r echo=TRUE}
df_accidentes
modelo_lda <- lda(formula = as.factor(grave) ~ 
                       antigüedad + edad.conductor + potencia, data = df_accidentes_train)
modelo_lda
summary(modelo_lda)
```

#Efectuamos las predicciones y matriz de confusión en el conjunto de entrenamiento.
```{r echo=TRUE}
datos_train = df_accidentes_train
pred_lda_train <- predict(modelo_lda,datos_train)
table(df_accidentes_train$grave, pred_lda_train$class, dnn = c("Clase real","Clase predicha"))
```

#Tasa de error en entrenamiento
```{r}
trainig_error <- mean(df_accidentes_train$grave != pred_lda_train$class) * 100 
trainig_error#0%
```

#Cambiando el umbral de corte.
```{r echo=TRUE}
pred_lda_train_2 = ifelse(pred_lda_train$posterior[,1]>0.,0,1)    
table(df_accidentes_train$grave, pred_lda_train_2, dnn = c("Clase real","Clase predicha"))
```

#Tasa de error en entrenamiento seleccionando otro umbral
```{r}
trainig_error <- mean(df_accidentes_train$grave != pred_lda_train_2) * 100 
trainig_error#0%
```
#Efectuamos las predicciones y matriz de confusión en el conjunto de validación.
```{r echo=TRUE}
datos_val = df_accidentes_val
pred_lda_val <- predict(modelo_lda,datos_val)
table(df_accidentes_val$grave, pred_lda_val$class, dnn = c("Clase real","Clase predicha"))
```

#Tasa de error en validación
```{r}
val_error <- mean(df_accidentes_val$grave != pred_lda_val$class) * 100 
val_error#0%
```

#Matriz de confusión LDA validación
```{r echo=TRUE}
a = factor( pred_lda_val$class, levels=c("1","0") )
b = factor( df_accidentes_val$grave, levels=c("1","0") )
confusion_lda = confusionMatrix(a, b)
confusion_lda
```

#QDA
```{r echo=TRUE}
modelo_qda <- qda(as.factor(df_accidentes_train$grave) ~ 
                   antigüedad + edad.conductor + potencia , data = datos_train)
modelo_qda
summary(modelo_qda)
```

#Efectuamos las predicciones y matriz de confusión en el conjunto de entrenamiento.
```{r echo=TRUE}
pred_qda_train <- predict(modelo_qda,datos_train)
table(df_accidentes_train$grave, pred_qda_train$class, dnn = c("Clase real","Clase predicha"))
```

#Tasa de error en entrenamiento
```{r}
trainig_error <- mean(df_accidentes_train$grave != pred_qda_train$class) * 100 
trainig_error#0%
```

#Efectuamos las predicciones y matriz de confusión en el conjunto de validación.
```{r echo=TRUE}
datos_val = df_accidentes_val[,c(2,3,4)]
pred_qda_val <- predict(modelo_qda, datos_val)
table(df_accidentes_val$grave, pred_qda_val$class, dnn = c("Clase real","Clase predicha"))
```

#Tasa de error en validación
```{r}
val_error <- mean(df_accidentes_val$grave != pred_qda_val$class) * 100 
val_error#0%
```

#Matriz de confusión QDA
```{r echo=TRUE}
a = factor( pred_qda_val$class, levels=c("1","0") )
b = factor( df_accidentes_val$grave, levels=c("1","0") )
confusion_qda = confusionMatrix(a,b)
confusion_qda
```

#Regla del discriminante cuadrático robusto
```{r}
cov.gen=cov.rob(df_accidentes_train[df_accidentes_train$grave==0,c(2,3)],method="mcd",
nsamp="best")
cov.apo=cov.rob(df_accidentes_train[df_accidentes_train$grave==1,c(2,3)],method="mcd",
nsamp="best")

#Realiza las estimaciones robustas
prom.gen=rep(cov.gen$center,100)
prom.apo=rep(cov.apo$center,100)
var.gen=as.matrix(cov.gen$cov)
var.apo=as.matrix(cov.apo$cov)

#Guarda las estimaciones
DR.gen=as.matrix(df_accidentes_train[,c(2,3)]-prom.gen)%*%solve(var.gen)%*%
t(as.matrix(df_accidentes_train[,c(2,3)]-prom.gen))
DR.apo=as.matrix(df_accidentes_train[,c(2,3)]-prom.apo)%*%solve(var.apo)%*%
t(as.matrix(df_accidentes_train[,c(2,3)]-prom.apo))

#Calcula las distancias de Mahalanobis robustas
clase=0
for(i in 1:nrow(df_accidentes_train[,c(2,3)])){
ifelse(DR.gen[i]<DR.apo[i],clase[i]<-0,clase[i]<-1)}

#Clasifica con las distancias
table(df_accidentes_train$grave,clase)

#Compara las clasificaciones originales con las robustas
trainig_error <- mean(df_accidentes_train$grave != clase) * 100 
trainig_error#0%
```

#Predicciones en validación
```{r}
clase2=0
DR.gen=as.matrix(df_accidentes_val[,c(2,3)]-prom.gen)%*%solve(var.gen)%*%
t(as.matrix(df_accidentes_val[,c(2,3)]-prom.gen))
DR.apo=as.matrix(df_accidentes_val[,c(2,3)]-prom.apo)%*%solve(var.apo)%*%
t(as.matrix(df_accidentes_val[,c(2,3)]-prom.apo))
for(i in 1:nrow(df_accidentes_val[,c(2,3)])){
ifelse(DR.gen[i]<DR.apo[i],clase2[i]<-0,clase2[i]<-1)}
#Clasifica con las distancias
table(df_accidentes_val$grave,clase2)
#Compara las clasificaciones originales con las robustas
trainig_error <- mean(df_accidentes_val$grave != clase2) * 100 
trainig_error#0%
```

```{r}
a = factor( clase2, levels=c("1","0") )
b = factor( df_accidentes_val$grave, levels=c("1","0") )
confusion_qda_robusto = confusionMatrix(a, b)
confusion_qda_robusto
```

#Regresión logistica con aquellas numéricas significativas
```{r echo=TRUE}
modelo_lg <- glm(as.factor(df_accidentes_train$grave) ~ 
                   
    antigüedad + edad.conductor + potencia , data = df_accidentes_train,family=binomial)
summary(modelo_lg)
```

#Predicciones en entrenamiento y matriz de confusión
```{r echo=TRUE}
pred_lg_train  <- predict(modelo_lg,type = "response")
clase_lg_train  = ifelse(pred_lg_train>0.5,1,0)  
table(df_accidentes_train$grave, clase_lg_train, dnn = c("Clase real","Clase predicha"))
```

#Matriz de confusión Regresión logística entrenamiento
```{r echo=TRUE}
a = factor( clase_lg_train, levels=c("1","0") )
b = factor( df_accidentes_train$grave, levels=c("1","0") )
confusion_logit = confusionMatrix(a,b)
confusion_logit
```
#Predicción validación
```{r echo=TRUE}
pred_lg_val  <- predict(modelo_lg,df_accidentes_val,type = "response")
clase_lg_val  = ifelse(pred_lg_val>0.5,1,0)  
table(df_accidentes_val$grave, clase_lg_val, dnn = c("Clase real","Clase predicha"))
```

#Matriz de confusión Regresión logística en validación
```{r echo=TRUE}
a = factor( clase_lg_val, levels=c("1","0") )
b = factor( df_accidentes_val$grave, levels=c("1","0") )
confusion_logit = confusionMatrix(a, b)
confusion_logit
```

#Regresión logistica 2. Modelo más simple, considerando sólo antigüedad
```{r echo=TRUE}
modelo2_lg <- glm(as.factor(grave) ~  
    antigüedad, data = df_accidentes_train,family=binomial)
summary(modelo2_lg)
```

#Matriz de confusión en conjunto de entrenamiento
```{r echo=TRUE}
pred2_lg_train  <- predict(modelo2_lg,type = "response")
clase2_lg_train  = ifelse(pred2_lg_train>0.5,1,0)    
table(df_accidentes_train$grave, clase2_lg_train, dnn = c("Clase real","Clase predicha"))
```

#Matriz de confusión Regresión logística (antigüedad)
```{r echo=TRUE}
a = factor( clase2_lg_train, levels=c("1","0") )
b = factor( df_accidentes_train$grave, levels=c("1","0") )
confusion_logit = confusionMatrix(a, b)
confusion_logit
```

#Matriz de confusión en conjunto de validación(antigüedad)
```{r echo=TRUE}
pred2_lg_val  <- predict(modelo2_lg,df_accidentes_val,type = "response")
clase2_lg_val  = ifelse(pred2_lg_val>0.5,1,0)    
table(df_accidentes_val$grave, clase2_lg_val, dnn = c("Clase real","Clase predicha"))
```

#Matriz de confusión Regresión logística
```{r echo=TRUE}
a = factor( clase2_lg_val, levels=c("1","0") )
b = factor( df_accidentes_val$grave, levels=c("1","0") )
confusion_logit = confusionMatrix(a, b)
confusion_logit
```

#Regresión logistica 3. Modelo más simple, considerando sólo edad.conductor
```{r echo=TRUE}
modelo3_lg <- glm(as.factor(grave) ~  edad.conductor , data = df_accidentes_train,family=binomial)
summary(modelo3_lg)
```

#Matriz de confusión en conjunto de entrenamiento
```{r echo=TRUE}
pred3_lg_train  <- predict(modelo3_lg,type = "response")
clase3_lg_train  = ifelse(pred3_lg_train>0.5,1,0) 
table(df_accidentes_train$grave, clase3_lg_train, dnn = c("Clase real","Clase predicha"))
```

#Matriz de confusión Regresión logística
```{r echo=TRUE}
a = factor( clase3_lg_train, levels=c("1","0") )
b = factor( df_accidentes_train$grave, levels=c("1","0") )
confusion_logit = confusionMatrix(a, b)
confusion_logit
```

#Matriz de confusión en conjunto de validación
```{r echo=TRUE}
pred3_lg_val  <- predict(modelo3_lg,df_accidentes_val,type = "response")
clase3_lg_val  = ifelse(pred3_lg_val>0.5,1,0)    
table(df_accidentes_val$grave, clase3_lg_val, dnn = c("Clase real","Clase predicha"))
```

#Matriz de confusión Regresión logística
```{r echo=TRUE}
a = factor( clase3_lg_val, levels=c("1","0") )
b = factor( df_accidentes_val$grave, levels=c("1","0") )
confusion_logit = confusionMatrix(a, b)
confusion_logit
```
#SVM
```{r echo=TRUE}
#Modelo support vector machine svm
modelo_svm=svm(as.factor(grave)~antigüedad + edad.conductor + potencia, 
               data=df_accidentes_train,method="C-classification",kernel="radial",cost=1,gamma=0.9)
pred_svm=predict(modelo_svm, df_accidentes_train)
table(df_accidentes_train$grave, pred_svm, dnn = c("Clase real", "Clase predicha"))
error_svm<- mean(df_accidentes_train$grave!= pred_svm) * 100
error_svm
```

#Matriz de confusión SVM
```{r echo=TRUE}
a = factor( pred_svm, levels=c("1","0") )
b = factor( df_accidentes_train$grave, levels=c("1","0") )
confusion_svm = confusionMatrix(a, b)
confusion_svm
```

#SVM en validación
```{r echo=TRUE}
#Modelo support vector machine svm
pred_svm_val=predict(modelo_svm,df_accidentes_val)
table(df_accidentes_val$grave, pred_svm_val, dnn = c("Clase real", "Clase predicha"))
error_svm<- mean(df_accidentes_val$grave!= pred_svm_val) * 100
error_svm

```

#Matriz de confusión SVM en validación
```{r echo=TRUE}
a = factor( pred_svm_val, levels=c("1","0") )
b = factor( df_accidentes_val$grave, levels=c("1","0") )
confusion_svm = confusionMatrix(a, b)
confusion_svm
```

#Comparación de predicciones de diferentes modelos:
```{r}
lda_val=pred_lda_val$posterior[,2]
qda_val=pred_qda_val$posterior[,2]
predicciones_varias = cbind(lda_val,
                            qda_val,
                            pred_lg_val,
                            pred2_lg_val,
                            pred3_lg_val,
                            pred_svm_val)
cor(predicciones_varias)

```

#ROC y AUC
```{r}

df_accidentes_val$grave

p1 <- prediction(as.data.frame(pred_qda_val$posterior)[,2], df_accidentes_val$grave) %>%
  performance(measure = "tpr", x.measure = "fpr")

p2 <- prediction(pred_lg_val, df_accidentes_val$grave) %>%
  performance(measure = "tpr", x.measure = "fpr")

p3 <- prediction(pred2_lg_val, df_accidentes_val$grave) %>%
  performance(measure = "tpr", x.measure = "fpr")

p4 <- prediction(pred3_lg_val, df_accidentes_val$grave) %>%
  performance(measure = "tpr", x.measure = "fpr")

plot(p1, col = "red")
plot(p2, add = TRUE, col = "blue")
plot(p3, add = TRUE, col = "darkgreen")
plot(p4, add = TRUE, col = "gold")
legend(x = "bottomright",legend =  c("QDA","Regresión Logística (antigüedad + edad.conductor)","Regresión Logística (antigüedad)","Regresión Logística (edad.conductor)"),fill = c("red","blue","darkgreen","gold","black"), title = "Modelos")
title(main = "Curvas ROC")


#AUC
auc= data.frame( c(
round(as.numeric(performance(prediction(as.data.frame(pred_qda_val$posterior)[,2], df_accidentes_val$grave), measure = "auc")@y.values),4),
round(as.numeric(performance(prediction(pred_lg_val, df_accidentes_val$grave), measure = "auc")@y.values),4),
round(as.numeric(performance(prediction(pred2_lg_val, df_accidentes_val$grave), measure = "auc")@y.values),4),
round(as.numeric(performance(prediction(pred3_lg_val, df_accidentes_val$grave), measure = "auc")@y.values),4)))
rotulo = data.frame(c("QDA","Regresión Logística (antigüedad + edad.conductor)","Regresión Logística (antigüedad)","Regresión Logística (edad.conductor)"))
tabla= cbind(rotulo,auc)
names(tabla)=c("Modelo","AUC")
tabla

```

# Clasificación  NO supervisada

```{r}
df_telecom <- read_excel(here::here("ds","bases.xlsx"), sheet = "telecomunicaciones")
df_telecom <- df_telecom[, c(1,3,7,29,34)]
df_telecom_procesado = df_telecom
df_telecom_values=df_telecom_procesado
df_telecom_procesado
```


#Análisis exploratorio
#Histogramas
```{r echo=TRUE}
par(mfcol = c(1,length(df_telecom_values)))
    for (k in 1:length(df_telecom_values)){
      boxplot(df_telecom_values[k],main = names(df_telecom_values[k]))
      grid()
    }
```

#Estandarizo datos y grafico boxplots
```{r echo=TRUE}
datos_estandarizados = data.frame(scale(df_telecom_values))
boxplot(datos_estandarizados)
```

#Dispersograma
```{r echo=TRUE}
pairs(datos_estandarizados)
```

#Matriz de correlaciones
```{r echo=TRUE}
matriz_de_correlaciones = data.frame(round(cor(df_telecom_values),2))
matriz_de_correlaciones
```

#Selecciono el par de variables más correlacionadas entre sí (internet / facturacion_electronica), calculamos el promedio de correlación con las demás variables.
```{r}
mean(abs(matriz_de_correlaciones$internet))
mean(abs(matriz_de_correlaciones$facturación_electrónica))
```

#A partir del análisis eliminamos la variable que presenta mayor correlación promedio con las demás variables (internet)
```{r}
#df_telecom_procesado = df_telecom_procesado[,-4]
#df_telecom_values=df_telecom_procesado[,c(1:4)]
df_telecom_procesado
df_telecom_values
```


#Calculamos la matriz de correlaciones y graficamos correlograma
```{r}
matriz_de_correlaciones = cor(df_telecom_values)
matriz_de_correlaciones
corrplot(matriz_de_correlaciones, method = "number")
```

#Autovalores
```{r echo=TRUE}
desc_mat_cor = eigen(matriz_de_correlaciones)
autovalores_cor = desc_mat_cor$values
round(autovalores_cor,2)
```

#Variabilidad explicada por cada autovalor
```{r echo=TRUE}
variabilidad_cor = autovalores_cor/sum(autovalores_cor)
round(variabilidad_cor,2)
```
# Las primeras dos componentes explican mas de un 60% de la variabilidad. 

#PCA
```{r echo=TRUE}
datos.pc = prcomp(df_telecom_values,scale = TRUE)
round(datos.pc$sdev^2,2)
```

#Autovectores (en columna)
```{r s, echo=TRUE}
round(datos.pc$rotation,2) 
```
#Vector de medias
```{r echo=TRUE}
round(datos.pc$center,2) #vector de medias 
```
#Vector de desvíos
```{r echo=TRUE}
round(datos.pc$scale,2) #vector de desvíos
```
#Loadings
```{r echo=TRUE}
carga1 = data.frame(cbind(X=1:length(df_telecom_values),
                          primeracarga=data.frame(datos.pc$rotation)[,1]))
carga2 = data.frame(cbind(X=1:length(df_telecom_values),
                          segundacarga=data.frame(datos.pc$rotation)[,2]))
round(cbind(carga1,carga2),2)
```
#Primera carga
```{r echo=TRUE}
ggplot(carga1, aes(X,primeracarga) ,
       fill=tramo ) + geom_bar ( stat="identity" ,
       position="dodge" ,
       fill ="royalblue" ,
       width =0.5 ) + xlab( 'Tramo' ) + ylab('Primeracarga ' )

```
#Segunda carga
```{r echo=TRUE}
ggplot( carga2 , aes ( X , segundacarga ) ,
        fill =X ) + geom_bar ( stat="identity" , position="dodge" ,
           fill ="royalblue" ,
           width =0.5 ) +
xlab('Tramo') + ylab('Segundacarga')

```

#Biplot
```{r echo=TRUE}
ggbiplot(datos.pc, labels = df_telecom_procesado$internet, labels.size = 2.5, obs.scale=1 ,var.scale=1,alpha=1.0) #cambiando el alfa?
str(datos.pc)
```

#Análisis de cluster
#Definición de funciones
```{r}
# se define función de escalamiento diferente de la tipica normal.
esc01 <- function(x) { (x - min(x)) / (max(x) - min(x))} 
# se define una funcion para calcular metricas que orientan sobre el número de clusters a elegir para el problema.
metrica = function(datA_esc,kmax,f) {
  
  sil = array()
  #sil_2 = array()
  sse = array()
  
  datA_dist= dist(datA_esc,method = "euclidean", diag = FALSE, upper = FALSE, p = 2)
  for ( i in  2:kmax) {
    if (strcmp(f,"kmeans")==TRUE) {   #centroide: tipico kmeans
      CL  = kmeans(datA_esc,centers=i,nstart=50,iter.max = kmax)
      sse[i]  = CL$tot.withinss 
      CL_sil = silhouette(CL$cluster, datA_dist)
      sil[i]  = summary(CL_sil)$avg.width
        }
    if (strcmp(f,"pam")==TRUE){       #medoide: ojo porque este metodo tarda muchisimo 
      CL = pam(x=datA_esc, k=i, diss = F, metric = "euclidean")
      sse[i]  = CL$objective[1] 
      sil[i]  = CL$silinfo$avg.width
      }
  }
  sse
  sil
  return(data.frame(sse,sil))
}
```

#Cantidad de clusters
```{r echo=TRUE}
kmax = 6
#2 opciones de escalamiento
#m1   = metrica(apply(datos,2,esc01),kmax,"kmeans")      #definida en la funcion esc01
m1   = metrica(scale(df_telecom_values),kmax,"kmeans")               #tipica de la normal
```

#Gráficos de los indicadores de clustering
```{r echo=TRUE}
par(mfrow=c(2,1))
plot(2:kmax, m1$sil[2:kmax],col=1,type="b", pch = 19, frame = FALSE, 
	 xlab="Number of clusters K",
	 ylab="sil") 

plot(2:kmax, m1$sse[2:kmax],type="b", pch = 19, frame = FALSE, 
	 xlab="Number of clusters K",
	 ylab="sse") 

par(mfrow=c(1,1))

```

#Criterio F cantidad de clusters. De 2 a 3 resulta significativo.   
```{r}
n=nrow(df_telecom_procesado)
k=2
(m1$sse[k]-m1$sse[k+1])/(m1$sse[k+1]/(n-k-1))
qf(0.05, k+1, n, lower.tail=F)
```

#elegimos realizar 3 grupos dado que el silouette es alto y se produce la baja más abrupta de la suma de cuadrados dentro del grupo
#Cluster por K-means
```{r echo=TRUE}
#elegimos realizar 3 grupos
CL  = kmeans(scale(df_telecom_values),3,nstart=50,iter.max = 100)
#CL  = kmeans(apply(datos,2,esc01),3,nstart=50,iter.max = 10)
df_telecom_values$kmeans = CL$cluster
```

#Visualizamos el cluster en dos variables, tasa de mortalidad y pnb
```{r echo=TRUE}
plot(df_telecom_values$edad,df_telecom_values$internet,col=df_telecom_values$kmeans)+
grid()
```

#Es posible visualizarlo mejor en un biplot con las primeras dos componentes principales.
```{r echo=TRUE}
ggbiplot(datos.pc, obs.scale=1 ,var.scale=1, alpha=0.5,groups = as.factor(df_telecom_values$kmeans), labels=df_telecom_procesado$paisesbaj )+
theme(legend.direction ="horizontal", legend.position = "top")
```

```{r}
ggbiplot(datos.pc, obs.scale=1 ,var.scale=1, alpha=1,groups = as.factor(df_telecom_values$kmeans) )+
theme(legend.direction ="horizontal", legend.position = "top")
```

#Nueva visualización
```{r echo=TRUE}
#lo hacemos finalmente para 3 grupos y lo visualizamos en un biplot
CL  = kmeans(scale(df_telecom_values),3,nstart=50,iter.max = 10)
df_telecom_values$kmeans = CL$cluster

ggbiplot(datos.pc, obs.scale=1 ,var.scale=1, alpha=0.5,groups = as.factor(df_telecom_values$kmeans) )+
  scale_color_manual(name="Cluster kmeans", values=c("orange", "cyan","grey"),labels=c("grupo 1", "grupo 2","grupo 3")) +  
theme(legend.direction ="horizontal", legend.position = "top")
```

#Cluster jerárquico, aglomerativo, considerando distancia euclidea, y distintos métodos de distancia a los clusters.
```{r echo=TRUE}
datos2=df_telecom_values[,-6]#quito columna "kmeans"
datos2=scale(datos2)

# Matriz de distancias euclídeas 
mat_dist <- dist(x = datos2, method = "euclidean") 

# Dendrogramas (según el tipo de segmentación jerárquica aplicada)  
hc_average  <- hclust(d = mat_dist, method = "average")
hc_single   <- hclust(d = mat_dist, method = "single")
hc_ward     <- hclust(d = mat_dist, method = "ward.D2")
#calculo del coeficiente de correlacion cofenético
cor(x = mat_dist, cophenetic(hc_average))
cor(x = mat_dist, cophenetic(hc_single))
cor(x = mat_dist, cophenetic(hc_ward))
```
#El método de average nos da el mejor valor de correlación cofenética, no obstante nos quedaría un grupo con un único país.

#Dendrograma con la técnica average
```{r echo=TRUE}
# construccion de un dendrograma usando los resultados de la técnica de average
plot(hc_average, labels = df_telecom_procesado$edad, cex=0.6)#no se ve bien si hay muchos datos
rect.hclust(hc_average, k=3, border="red")#con 3 grupos
grupos<-cutree(hc_average,k=3)#con 3 grupos
#split(rownames(datos),grupos)#devuelve una lista con las observaciones separadas por grupo
```

#Dendrograma con la técnica ward
```{r echo=TRUE}
# # construccion de un dendrograma usando los resultados de la técnica de Ward
plot(hc_ward, labels = df_telecom_procesado$edad, cex=0.6)#no se ve bien si hay muchos datos
rect.hclust(hc_ward, k=3, border="red")#con 3 grupos
grupos<-cutree(hc_ward,k=3)#con 3 grupos
grupos[grupos==2]=4
grupos[grupos==3]=2
grupos[grupos==4]=3
# #split(rownames(datos),grupos)#devuelve una lista con las observaciones separadas por grupo
```

#Visualizamos con 3 grupos el cluster jerárquico
```{r echo=TRUE}
ggbiplot(datos.pc, obs.scale=1 ,var.scale=1, alpha=0.5,groups = as.factor(grupos))+
  scale_color_manual(name="Cluster jerárquico Ward", values=c("red", "blue","green"),labels=c("grupo 1", "grupo 2", "grupo 3")) +  
theme(legend.direction ="horizontal", legend.position = "top")
```


#Boxplots de cada variable por grupo
```{r}
variables=df_telecom_values
names(variables)[6]="cluster"
#variables$cluster=factor(variables$cluster)
variables$cluster=factor(grupos)


ggplot(variables,aes(x=cluster,y=region,fill=cluster))+
geom_boxplot()+
xlab("")+
scale_fill_brewer(palette="Pastel1",name="Cluster",
breaks=c("1","2","3"),labels=c("1","2","3"))+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())
ggplot(variables,aes(x=cluster,y=edad,fill=cluster))+
geom_boxplot()+
xlab("")+
scale_fill_brewer(palette="Pastel1",name="Cluster",
breaks=c("1","2","3"),labels=c("1","2","3"))+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())
ggplot(variables,aes(x=cluster,y=nivel_educativo,fill=cluster))+
geom_boxplot()+
xlab("")+
scale_fill_brewer(palette="Pastel1",name="Cluster",
breaks=c("1","2","3"),labels=c("1","2","3"))+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())
ggplot(variables,aes(x=cluster,y=internet,fill=cluster))+
geom_boxplot()+
xlab("")+
scale_fill_brewer(palette="Pastel1",name="Cluster",
breaks=c("1","2","3"),labels=c("1","2","3"))+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())
ggplot(variables,aes(x=cluster,y=facturación_electrónica,fill=cluster))+
geom_boxplot()+
xlab("")+
scale_fill_brewer(palette="Pastel1",name="Cluster",
breaks=c("1","2","3"),labels=c("1","2","3"))+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank())
```

#Dispersograma de las variables numéricas, mostrando a que cluster pertenecen 
```{r}
pairs(x = variables[, c(1,2,3,4,5)], col = c("firebrick", "blue","green3")[variables$cluster], pch = 19)
```
